{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- Nuha Alghamdi --\n",
    "### -- nuhaalghamdi92@gmail.com --\n",
    "### -- Feb 22 2020 --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "#for precision, recall and f score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose one cell to run  from 1 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "#1\n",
    "#Vectors are generated by gensim wrapper.fastText+whole text\n",
    "X = np.load('X_vecs.npy')\n",
    "y = np.load('y_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1909, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1909,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "#2\n",
    "#Vectors are generated by gensim wrapper.fastText words+avg\n",
    "X = np.load('X_vecs_tokenized.npy')\n",
    "y = np.load('y_labels_tokenized.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "#3\n",
    "#Vectors are generated by gensim implementation of fastText+whole text\n",
    "X = np.load('X_vecs_gen.npy')\n",
    "y = np.load('y_labels_gen.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "#4\n",
    "#Vectors are generated by gensim implementation of fastText words+avg\n",
    "X = np.load('X_vecs_tokenized_gen.npy')\n",
    "y = np.load('y_labels_tokenized_gen.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5\n",
    "#Vectors are generated by fastText library (vs)\n",
    "X = np.load('X_vecs_fastText_vs.npy')\n",
    "y = np.load('y_labels_fastText_vs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6\n",
    "#Vectors are generated by fastText library (vw)\n",
    "X = np.load('X_vecs_fastText_vw.npy')\n",
    "y = np.load('y_labels_fastText_vw.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-Folds to do cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold \n",
    "#Stratisifed =Takes group information into account to avoid building folds with\n",
    "#imbalanced class distributions (for binary or multiclass classification tasks).\n",
    "skf = StratifiedKFold(n_splits=10,random_state=42)\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=42, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "print(skf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_Xfolds=[]\n",
    "array_yfolds=[]\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    array_Xfolds.append(X_train)\n",
    "    array_Xfolds.append(X_test)\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    array_yfolds.append(y_train)\n",
    "    array_yfolds.append(y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "1718 191\n"
     ]
    }
   ],
   "source": [
    "#len must be 10\n",
    "print(len(array_Xfolds))\n",
    "print(len(array_yfolds))\n",
    "#length of each fold\n",
    "print(len(array_Xfolds[0]),len(array_Xfolds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 2: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 3: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 4: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 5: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 6: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 7: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 8: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 9: X_train: 1718 X_test:  191\n",
      "        y_train: 1718 y_test:  191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 10: X_train: 1719 X_test:  190\n",
      "         y_train: 1719 y_test:  190\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Fold 1:\n",
    "print('Fold 1: X_train:', len(array_Xfolds[0]),'X_test: ', len(array_Xfolds[1]))\n",
    "print('        y_train:', len(array_yfolds[0]),'y_test: ', len(array_Xfolds[1]))\n",
    "print('-'*100)\n",
    "#Fold 2:\n",
    "print('Fold 2: X_train:', len(array_Xfolds[2]),'X_test: ', len(array_Xfolds[3]))\n",
    "print('        y_train:', len(array_yfolds[2]),'y_test: ', len(array_Xfolds[3]))\n",
    "print('-'*100)\n",
    "#Fold 3:\n",
    "print('Fold 3: X_train:', len(array_Xfolds[4]),'X_test: ', len(array_Xfolds[5]))\n",
    "print('        y_train:', len(array_yfolds[4]),'y_test: ', len(array_Xfolds[5]))\n",
    "print('-'*100)\n",
    "#Fold 4:\n",
    "print('Fold 4: X_train:', len(array_Xfolds[6]),'X_test: ', len(array_Xfolds[7]))\n",
    "print('        y_train:', len(array_yfolds[6]),'y_test: ', len(array_Xfolds[7]))\n",
    "print('-'*100)\n",
    "#Fold 5:\n",
    "print('Fold 5: X_train:', len(array_Xfolds[8]),'X_test: ', len(array_Xfolds[9]))\n",
    "print('        y_train:', len(array_yfolds[8]),'y_test: ', len(array_Xfolds[9]))\n",
    "print('-'*100)\n",
    "#Fold 6:\n",
    "print('Fold 6: X_train:', len(array_Xfolds[10]),'X_test: ', len(array_Xfolds[11]))\n",
    "print('        y_train:', len(array_yfolds[10]),'y_test: ', len(array_Xfolds[11]))\n",
    "print('-'*100)\n",
    "#Fold 7:\n",
    "print('Fold 7: X_train:', len(array_Xfolds[12]),'X_test: ', len(array_Xfolds[13]))\n",
    "print('        y_train:', len(array_yfolds[12]),'y_test: ', len(array_Xfolds[13]))\n",
    "print('-'*100)\n",
    "#Fold 8:\n",
    "print('Fold 8: X_train:', len(array_Xfolds[14]),'X_test: ', len(array_Xfolds[15]))\n",
    "print('        y_train:', len(array_yfolds[14]),'y_test: ', len(array_Xfolds[15]))\n",
    "print('-'*100)\n",
    "#Fold 9:\n",
    "print('Fold 9: X_train:', len(array_Xfolds[16]),'X_test: ', len(array_Xfolds[17]))\n",
    "print('        y_train:', len(array_yfolds[16]),'y_test: ', len(array_Xfolds[17]))\n",
    "print('-'*100)\n",
    "#Fold 10:\n",
    "print('Fold 10: X_train:', len(array_Xfolds[18]),'X_test: ', len(array_Xfolds[19]))\n",
    "print('         y_train:',  len(array_yfolds[18]),'y_test: ', len(array_Xfolds[19]))\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for train_index, test_index in skf.split(X, y):\n",
    "#    print(\"Len of TRAIN:\", len(train_index), \"Len of TEST:\", len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select one cell to run, each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 1\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[0],array_Xfolds[1],array_yfolds[0],array_yfolds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 2\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[2],array_Xfolds[3],array_yfolds[2],array_yfolds[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 3\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[4],array_Xfolds[5],array_yfolds[4],array_yfolds[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 4\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[6],array_Xfolds[7],array_yfolds[6],array_yfolds[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 5\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[8],array_Xfolds[9],array_yfolds[8],array_yfolds[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 6\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[10],array_Xfolds[11],array_yfolds[10],array_yfolds[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 7\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[12],array_Xfolds[13],array_yfolds[12],array_yfolds[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 8\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[14],array_Xfolds[15],array_yfolds[14],array_yfolds[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 9\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[16],array_Xfolds[17],array_yfolds[16],array_yfolds[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fold 10\n",
    "X_train,X_test,y_train,y_test=array_Xfolds[18],array_Xfolds[19],array_yfolds[18],array_yfolds[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831578947368\n",
      "(0.84184123431429148, 0.82666666666666655, 0.83112355144483663, None)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                             random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred=clf.predict(X_test)\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tf18\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905263157895\n",
      "(0.90555313588850184, 0.90833333333333344, 0.90584684947207905, None)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classifier\n",
    "clf = LogisticRegressionCV(multi_class='multinomial', verbose=3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred=clf.predict(X_test)\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.910526315789\n",
      "(0.91307080016757447, 0.91333333333333333, 0.91124646031998169, None)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "print(svm_model_linear.score(X_test,y_test))\n",
    "y_pred=svm_model_linear.predict(X_test)\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889473684211\n",
      "(0.89307197307197295, 0.89166666666666661, 0.8918562594141477, None)\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 3).fit(X_train, y_train) \n",
    "print(knn.score(X_test,y_test))\n",
    "y_pred=knn.predict(X_test)\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842105263158\n",
      "(0.85190831907110987, 0.83833333333333349, 0.8425356715861998, None)\n"
     ]
    }
   ],
   "source": [
    "#NuSVC\n",
    "from sklearn.svm import NuSVC\n",
    "clf = NuSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred=clf.predict(X_test)\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731578947368\n",
      "(0.73676518199013952, 0.7433333333333334, 0.73504922307739218, None)\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0).fit(X_train,y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred=clf.predict(X_test)\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.82      0.86        40\n",
      "          1       0.93      0.93      0.93        30\n",
      "          2       0.90      0.88      0.89        40\n",
      "          3       0.93      0.97      0.95        40\n",
      "          4       0.81      0.85      0.83        40\n",
      "\n",
      "avg / total       0.89      0.89      0.89       190\n",
      "\n",
      "score: 0.8894736842105263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(300,400,300))\n",
    "clf = MLPClassifier(hidden_layer_sizes=(400,400,300))\n",
    "clf.fit(X_train,y_train)\n",
    "s = clf.score(X_test, y_test)\n",
    "predictions = clf.predict(X_test)\n",
    "print(f'results report:\\n {classification_report(y_test,predictions)}')\n",
    "print(f'score: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "#kernel = 1.0 * RBF(1.0)\n",
    "#gpc = GaussianProcessClassifier(multi_class = \"one_vs_one\", kernel=kernel,random_state=0).fit(X_train, y_train)\n",
    "#print(gpc.score(X_test, y_test))\n",
    "#y_pred=gpc.predict(X_test)\n",
    "#print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815789473684\n",
      "(0.82890849673202605, 0.81666666666666665, 0.81929271376639812, None)\n"
     ]
    }
   ],
   "source": [
    "#Gaussian NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred=clf.predict(X_test)\n",
    "print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0 j:  1\n",
      "0.890052356021\n",
      "(0.89793028810270192, 0.89064516129032256, 0.89305672718381324, None)\n",
      "i:  2 j:  3\n",
      "0.895287958115\n",
      "(0.89447552447552447, 0.89709677419354839, 0.8955537974683544, None)\n",
      "i:  4 j:  5\n",
      "0.869109947644\n",
      "(0.87619293548483168, 0.87209677419354836, 0.87282612528700965, None)\n",
      "i:  6 j:  7\n",
      "0.879581151832\n",
      "(0.88710533369069944, 0.88209677419354837, 0.88423705685720722, None)\n",
      "i:  8 j:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tf18\\lib\\site-packages\\sklearn\\gaussian_process\\gpc.py:430: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ 0.00027377, -0.00102606]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 12, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890052356021\n",
      "(0.89280540597613778, 0.89064516129032256, 0.89042842686558532, None)\n",
      "i:  10 j:  11\n",
      "0.869109947644\n",
      "(0.87979651927020353, 0.87064516129032266, 0.87411024026897299, None)\n",
      "i:  12 j:  13\n",
      "0.858638743455\n",
      "(0.86266312498870656, 0.86499999999999999, 0.862994359182232, None)\n",
      "i:  14 j:  15\n",
      "0.869109947644\n",
      "(0.8767957545236108, 0.87209677419354836, 0.87367469848482493, None)\n",
      "i:  16 j:  17\n",
      "0.890052356021\n",
      "(0.8925298231180584, 0.89209677419354827, 0.89037965911383632, None)\n",
      "i:  18 j:  19\n",
      "0.9\n",
      "(0.90052260052260069, 0.90500000000000003, 0.90137427826773142, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "kernel = 0.1 * RBF(1.0)\n",
    "i=0\n",
    "j=1\n",
    "for f in range(10): \n",
    "    print(\"i: \",i,\"j: \",j)\n",
    "    X_train,X_test,y_train,y_test=array_Xfolds[i],array_Xfolds[j],array_yfolds[i],array_yfolds[j]\n",
    "    #GaussianProcessClassifier\n",
    "    gpc = GaussianProcessClassifier(multi_class = \"one_vs_one\", kernel=kernel,random_state=0).fit(X_train, y_train)\n",
    "    print(gpc.score(X_test, y_test))\n",
    "    y_pred=gpc.predict(X_test)\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='macro'))\n",
    "    i=i+2\n",
    "    j=j+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\envs\\tf18\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "           random_state=42, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression classifier\n",
    "clf = LogisticRegressionCV(multi_class='multinomial', verbose=3, random_state=42)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(400, 400, 300), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "clf2 = MLPClassifier(hidden_layer_sizes=(400,400,300))\n",
    "clf2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GaussianProcessClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "gpc = GaussianProcessClassifier(multi_class = \"one_vs_one\", kernel=kernel,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "#save model\n",
    "#dump(gpc, 'Model_GPC_fT_vs.joblib') \n",
    "#load model\n",
    "#clf = load('filename.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model_GPC_fT_vs.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For sentences (LR, MLP, gpc)\n",
    "dump(clf, 'Model_LR_fT_vs.joblib') \n",
    "dump(clf2, 'Model_MLP_fT_vs.joblib') \n",
    "dump(gpc, 'Model_GPC_fT_vs.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model_GPC_fT_vw.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For Words (LR, MLP, gpc)\n",
    "dump(clf, 'Model_LR_fT_vw.joblib') \n",
    "dump(clf2, 'Model_MLP_fT_vw.joblib') \n",
    "dump(gpc, 'Model_GPC_fT_vw.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
